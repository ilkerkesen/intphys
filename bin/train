#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import os.path as osp

import torch
import torch.nn as nn
from torch.nn import functional as F
from torch.utils.data import DataLoader
import pytorch_lightning as pl
import hydra

from intphys import *
from intphys.data import train_collate_fn as collate_fn
from intphys.data import SimulationInput
from intphys.experiment import Experiment

CONFIG_DIR = osp.abspath(osp.join(__file__, "../..", "config"))


@hydra.main(config_path=osp.join(CONFIG_DIR, "train.yaml"), strict=False)
def train(config):
    config = pl.utilities.parsing.AttributeDict(config)
    pl.seed_everything(config["seed"])

    # load data
    train_data = IntuitivePhysicsDataset(split="train", **config["dataset"])
    val_data = IntuitivePhysicsDataset(split="validation", **config["dataset"])

    # logger / checkpoint
    config["logger"]["save_dir"] = osp.abspath(
        osp.expanduser(config["logger"]["save_dir"]))
    if config["logger"]["name"] is None:
        config["logger"]["name"] = config["model"]["architecture"]
    logger = pl.loggers.TensorBoardLogger(**config["logger"])
    config["checkpoint"]["filepath"] = osp.join(
        logger.log_dir, "checkpoints/{epoch:03d}")
    checkpoint_callback = pl.callbacks.ModelCheckpoint(**config["checkpoint"])

    # data dependent parameters
    if config["model"].get("input_size") is None:
        config["model"]["input_size"] = len(train_data.question_vocab)
    if config["model"].get("output_size") is None:
        config["model"]["output_size"] = len(train_data.answer_vocab)
    experiment = Experiment(config)

    # setup dataset params depend on model
    train_data.adapt2model(experiment.model)
    val_data.adapt2model(experiment.model)

    # simulation caching
    train_data.build_cache()
    val_data.build_cache()

    # create data loaders
    train_dataloader = DataLoader(train_data,
                                  shuffle=True,
                                  collate_fn=collate_fn,
                                  **config["loader"])
    val_dataloader = DataLoader(val_data,
                                shuffle=False,
                                collate_fn=collate_fn,
                                **config["loader"])


    # load pretrained if any
    if config["pretrained"] is not None:
        ckpt = torch.load(config["pretrained"])
        experiment.model.load_state_dict(ckpt["state_dict"], strict=False)

    # trainer
    trainer = pl.Trainer(
        logger=logger,
        checkpoint_callback=checkpoint_callback,
        **config["trainer"])

    # train
    if config["train"]:
        trainer.fit(
            experiment,
            train_dataloader=train_dataloader,
            val_dataloaders=val_dataloader)

    # test
    if config["test"]:
        test_data = IntuitivePhysicsDataset(split="test", **config["dataset"])
        test_data.adapt2model(experiment.model)
        test_dataloader = DataLoader(
            test_data,
            shuffle=False,
            collate_fn=collate_fn,
            **config["loader"])
        trainer.test(test_dataloaders=test_dataloader)


if __name__ == "__main__":
    train()
