# @package _group_
architecture: null
input_size: null
output_size: null
dropout: 0.0
question_encoder:
  architecture: LSTMEncoder
  hidden_size: 512
  embed_size: 512
  vocab_size: null
frame_encoder:
  architecture: resnet18
  input_size: 256
  pretrained: true
  freeze: false
  num_layers: 4
mlp:
  activation: relu
  num_layers: 2
  hidden_size: 512
  input_size: null